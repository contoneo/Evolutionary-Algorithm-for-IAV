{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The code is running using NumPy.  The functions used are also available with torch and tensorflow, but \n","if the Anaconda distribution of Python is installed, NumPy comes pre-installed and no further installation steps are necessary.\n","\n","In the following lines, we refer to this algorithm as \"**EA**\""]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":false},"outputs":[],"source":["import numpy as np"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["First, the variables needed for the implementation are set. The time unit in the implementation is milliseconds (*ms*)"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":false},"outputs":[],"source":["# number of iterations in the Step_2\n","step_2_iterations = 4\n","# for every matrix containing samples in the way (t_Start, t_End) the columns are then numerated:\n","t_start_column = 0\n","t_end_column = 1\n","# Possible offset of the range (T_Start, t_0) for the creation of samples in step_1\n","offset = 10\n","# Replace for zero to be able to calculate relative_fitness_value (reciprocal of value)\n","mindestwert\t= 0.0001\n","# Array of first samples.  It is needed to differentiate from the later array of results\n","first_test_samples = np.array([])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now, **EA** variables are set:\n","* In $V_1$ it is desirable to prioritize $| t_{End} − E_i |$ over $| t_{Start}− E_i |$, accordingly, *b* must be higher than *a* , thus $b > a$\n","* As $V_2$ corresponds with the main purpose of the test, this value should be correspondingly higher than $V_1$ , therefore $c > b > a$"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":false},"outputs":[],"source":["# T_Start: Instant when pre-crash recording time starts.\n","T_Start = -5000\n","# t_0: Instant when pre-crash recording time ends.  \n","# As t_0 is the time when the recording algorithm start, it is normally set to zero.\n","t_0 = 0\n","# T: Pre-crash recording time established in the regulation.\n","T = (T_Start, t_0)\n","# popsize: Population size in the Evolutive Algorithm.  Number of test samples created with the algorithm\n","popsize = 4\n","# lambda_new: New generated samples in each iteration\n","lambda_new = 2\n","# The value obtained from the minimum is divided by 1000 so that the value of V_1 is comparable with the of V_2 (next criteria).\n","V_1_scale = 0.001\n","\n","# For the fitness function:\n","a = 1  # Factor to weight | t_Start − E_i [ t_Start ] | in V_1\n","b = 3  # Factor to weight | t_End − E_i [ t_End ] | in V_1\n","c = 5  # Factor to weight V_2 over V_1\n","\n","# For the mutation function:\n","mu = 0  # Mean in normal distribution: for the standard normal distribution set in zero\n","sigma = 15 # Standard deviation in normal distribution: It is also known as the scale factor"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["`error_hit_set` (**Fehlertreff** in Excel sheet)  \n","Is the set with the samples, that have discovered an error within the test procedure.  At the beginning of the whole procedure the set is empty, but as the procedure discover errors in testing, it will be filled with them.\n","The next cell contains an example of a possible set of samples that had lead to an error (The same as given in Excel file)."]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":false},"outputs":[],"source":["# error_hit_set = np.array([[-4025, -300],[-3213, -1232]])\n","error_hit_set = np.array([])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["`initialize_samples_array`  \n","Create set of random test samples in the range $[T_{Start}$-`offset`$ , t_0$+`offset`$]$"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":false},"outputs":[],"source":["def initialize_samples_array():\n","    # Generate random values for the t_start values in the range [0,1]\n","    t_start = np.random.rand(popsize, 1)\n","    \n","    # Generate random values for the t_End values in the range [0,t_start]\n","    t_End = np.random.rand(popsize, 1) * t_start\n","    \n","    # Concatenate the columns to create the array of samples in the way (t_start, t_End)\n","    array = np.concatenate((t_start, t_End), axis=1)\n","    \n","    # Establish the array in the range from T_start to t_0 plus the offset and round to have only integers \n","    array = offset + np.rint(array * (T_Start - 2*offset))\n","    \n","    return array"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The fitness function\n","$$\n","f_i = V_1 + c \\cdot V_2\n","$$\n","is written for a test sample $i$.  To make it fit for use with a tests samples array the variables `samples` and `error_hit_set` are passing as arguments to the `fitness_function` function\n","\n","In turn,$V_1$ is defined as:\n","$$\n","V_1 = \\frac{\\displaystyle \\min_{i \\in S}(a \\cdot | t_{Start} - E_i[t_{Start}] |+ b \\cdot | t_{End} - E_i[t_{End}]|)} {V_1\\_scale}\n","$$\n","again, it is written for a test sample $i$.  In order to function with an array of test samples it takes `samples` and `error_hit_set` variables as arguments. The return of this fuction is the array of $V_1$ value for every sample given in `samples` variable.\n","* If ***E*** is empty, then $V_1 = 0$\n","\n","$V_2$ is defined as:\n","$$\n","V_2 =\n","\\begin{cases}\n","| t_{End} - T_{Start} | & \\text{if}  & t_{End} < T_{Start}\\\\\n","0 & \\text{if} & T_{Start} <= t_{End} <= t_0\\\\\n","| t_{End} - t_0 | & \\text{if} & t_0 < t_{End}\n","\\end{cases}\n","$$\n"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":false},"outputs":[],"source":["def fitness_function(samples, error_hit_set):\n","    res_V_1 = V_1(samples, error_hit_set) + c*V_2(samples)\n","\n","    return res_V_1\n","\n","def V_1(samples_array, error_hit_set):\n","    if error_hit_set.size == 0:  # if error_hit_set is empty\n","        return np.zeros(samples_array.shape[0]) # return an array filled with zeros\n","\n","    # weight (t_Start, E_i[t_Starμ]) and t_End, E_i[t_End] in the samples and error_hit_set matrices \n","    # with a and b correspondingly before the diffrence comparison between them \n","    weights = np.array([[a,b]])\n","    samples_weigthed = samples_array * weights\n","    error_hit_set_weigthed = error_hit_set * weights\n","    \n","    # Calculate the absolute difference between each row in samples_weigthed and all rows in error_hit_set\n","    diff = np.abs(samples_weigthed[:, None, :] - error_hit_set_weigthed)\n","\n","    # Sum the members for each sample case\n","    sum_evaluation = diff.sum(axis=2)\n","    \n","    # return the minimum for each case multiplied by V_1_scale\n","    return np.min(sum_evaluation, axis=1) * V_1_scale\n","\n","def V_2(samples_array):\n","    # Get the t_end of samples\n","    t_end = samples_array[:, t_end_column]\n","\n","    # If t_end>t_0 we return the difference, otherwise we return T_Start - t_end,\n","    # this last leaves negative results when T_Start <= t_end <= t_0, namely, when t_end is contained in T, thus:\n","    #\n","    # distance = np.where(t_end>t_0, t_end - t_0, T_Start - t_end)\n","    #\n","    # But as t_0 is set at zero then t_end - t_0 can be just t_end\n","    distance = np.where(t_end>t_0, t_end, T_Start - t_end)\n","    \n","    # We return only the positive numbers, as they are the ones not contained in the range [T_Start,t_0], \n","    # othewise we return zero\n","    return distance.clip(min=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["As the `fitness_function` evaluate the best samples with the minimum score, the `relative_fitness_value` takes the reciprocal ($f^-1$) of this value to do:\n","$$\n","p_i = \\frac{f_i}{\\displaystyle \\sum_{i=1}^{popsize} f_i}\n","$$\n","and returns an array of the `relative_fitness_value` for all samples."]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":false},"outputs":[],"source":["def relative_fitness_value(samples_score):\n","    # replace zeros in samples_score with \"mindestwert\" value that can be passed as an argument to np.reciprocal\n","    samples_score = np.where(samples_score == 0, mindestwert, samples_score)\n","    \n","    reciprocal = np.reciprocal(samples_score)\n","    reciprocal_sum = np.sum(reciprocal)\n","    result = reciprocal * (1 / reciprocal_sum)\n","    \n","    return result\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["`select_offspring` returns a `lambda_new` sized samples array based on **RWS** method"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":false},"outputs":[],"source":["def select_offspring(bins, samples, lambda_new):\n","    x = np.random.rand(lambda_new)\n","    #x = np.array([0.764859213377431, 0.615431627867042])  # random numbers used in the example\n","    #bins = np.array([0.25062546, 0.3624107,  0.25580673, 0.13115711])  # bins (p) in the example\n","    bins_cumulative = np.cumsum(bins)\n","    selection = np.digitize(x, bins_cumulative)\n","    samples_selected = samples[selection,:]\n","    \n","    return samples_selected"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["`mutate_selected_offspring` performs a mutation to the selected_offspring in order to generate new alternatives of samples"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mutate_selected_offspring(offspring_selection, samples):\n","    mutation = np.round(np.random.normal(mu, sigma, size=(lambda_new, 2))).astype(int)\n","    offspring = offspring_selection + mutation\n","\n","    # Find indices where t_start is greater than t_end\n","    indices = np.where(offspring[:, t_start_column] > offspring[:, t_end_column])[0]\n","\n","    # Swap the elements for the selected indices\n","    offspring[indices, :] = offspring[indices, ::-1]\n","    \n","    # Eliminate rows from offspring that are already present in samples\n","    offspring = np.array([row for row in offspring if not any(np.array_equal(row, row2) for row2 in samples)])\n","    \n","    return offspring"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["`select_new_generation` delivers the new generation of test samples made up of the best rated samples from the offspring + the previous set of samples."]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":false},"outputs":[],"source":["def select_new_generation(matrix, scores):\n","    # Sort the rows by ascending scores.\n","    # The lowest elements become the highest elements when an array is negated.\n","    sorted_indices = np.argsort(-scores)\n","    sorted_matrix = matrix[sorted_indices]\n","    \n","    # Select the top popsize samples\n","    best_samples = sorted_matrix[-popsize:]\n","    \n","    return best_samples"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["1. Random test samples creation\n","In order to maximize the exploration of possible errors, new random samples will be created, so that every time the test is executed, it will take new values to test. The restriction for the creation of test samples is the time range where the end of the trivial event can take place $T = (T_{Start}, t_0)$.  \n","Here, the values taken in the Excel file are given as substitute for the random renerated samples."]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":false},"outputs":[],"source":["def step_1():\n","    # samples = initialize_samples_array()\n","    samples = np.array([[-2420,-259],[-4338,-594],[-3616,-728],[-1311,-104]])\n","\n","    return samples"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["2. Test execution and following test sample creation process."]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":false},"outputs":[],"source":["def step_2(samples):\n","    # 2.1. Evaluation:\n","    #  After the first test execution, the test results are evaluated within the fitness function \n","    #  [Equation 6].\n","\n","    samples_score = fitness_function(samples, error_hit_set)\n","\n","    # 2.2. Offspring:\n","    #  Then, by means of Roulette wheel selection (RWS) method the samples to generate new samples\n","    #  (offspring) are selected.\n","\n","    p = relative_fitness_value(samples_score)  # The relative_fitness_value of each sample based on its sample_score\n","    offspring_selection = select_offspring(p, samples, lambda_new)  # A lambda_new sized samples array based on RWS method\n","    \n","    # 2.3. Mutation:\n","    #  In this case the \"Recombination\" phase does not take place, so directly the new samples are\n","    #  mutated by means of Normal mutation function [Equation 8] for each\n","    #  property of the new samples (t_Start, t_End ).\n","    offspring = mutate_selected_offspring(offspring_selection, samples)\n","\n","    # 2.4. Mutated Samples Evaluation:\n","    #  The new samples are evaluated within the fitness function.\n","    offspring_score = fitness_function(offspring, error_hit_set)\n","\n","    # 2.5. New generation:\n","    #  The best (popsize) evaluated test samples from the set of current and new test samples are\n","    #  taken for the next iteration of the process.\n","\n","    new_samples = np.concatenate((samples, offspring))\n","    new_scores = np.concatenate((samples_score, offspring_score))\n","    new_generation = select_new_generation(new_samples, new_scores)\n","\n","    return new_generation\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Then, the **EA** algorithm and its usage is:"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["[[-2420  -259]\n"," [-4338  -594]\n"," [-3616  -728]\n"," [-1311  -104]]\n","[[-4338  -593]\n"," [-4340  -591]\n"," [-4340  -591]\n"," [-4337  -588]]\n"]}],"source":["# Then, the EA algorithm is:\n","def EA():\n","    array = first_test_samples\n","    for _ in range(step_2_iterations):\n","        array = step_2(array)\n","    return array\n","\n","# Step 1\n","first_test_samples = step_1()\n","print(first_test_samples)\n","# Step 2 iterations\n","test_samples = EA()\n","print(test_samples)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":2}
